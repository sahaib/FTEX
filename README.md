# ğŸ« FTEX - Freshdesk Ticket Extraction & Analysis

> **Production-grade pipeline for extracting, analyzing, and generating actionable insights from Freshdesk support tickets using Self-Validating GenAI.**

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Ollama](https://img.shields.io/badge/Ollama-qwen3:14b-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Version](https://img.shields.io/badge/Version-6.0-orange.svg)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [What's New in v6.0](#whats-new-in-v60)
- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [CLI Reference](#cli-reference)
  - [test - Check API Connection](#test---check-api-connection)
  - [extract - Download Tickets](#extract---download-tickets)
  - [analyze - Run AI Analysis](#analyze---run-ai-analysis)
  - [full - Complete Pipeline](#full---complete-pipeline)
- [Output Files](#output-files)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
  - [Environment Variables](#environment-variables)
  - [Domain Customization (UserConfig)](#domain-customization-userconfig)
  - [SLA Configuration](#sla-configuration)
- [Analysis Pipeline](#analysis-pipeline)
- [Customization Examples](#customization-examples)
- [Troubleshooting](#troubleshooting)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

---

## Overview

FTEX is a comprehensive toolkit for support operations teams to:
- ğŸš€ **Extract** tickets from Freshdesk with checkpointing (survives interruptions)
- ğŸ§  **Analyze** using self-validating GenAI that discovers patterns from YOUR data
- ğŸ“Š **Generate** evidence-based reports with specific ticket IDs for immediate action

**Key Innovations in v6.0:**
- ğŸ¯ Every finding backed by evidence (ticket IDs)
- ğŸ” AI self-validation (challenges its own conclusions)
- ğŸ’¡ Solution quality analysis (evaluates how well issues were resolved)
- ğŸ”§ Fully configurable for any product/domain (maritime, retail, SaaS, IoT)

---

## What's New in v6.0

| Before (v5) | Now (v6) |
|-------------|----------|
| 4 separate analysis scripts | 1 unified `analyze.py` |
| Hardcoded categories | AI discovers categories from YOUR data |
| Trust AI output | Self-validating with confidence scores |
| Generic reports | Evidence-based findings with ticket IDs |
| Domain-specific code | Configurable via `UserConfig` class |
| Separate report generation | Single command generates all outputs |

---

## Features

### Extraction (`freshdesk_extractor_v2.py`)
- âœ… Incremental disk saves (each ticket saved immediately)
- âœ… Checkpoint/resume support (crash-safe)
- âœ… Rich terminal UI with live progress dashboard
- âœ… Weekly date chunking for optimal API usage
- âœ… Rate limit monitoring and auto-throttling
- âœ… Optional attachment downloads

### Smart Detection Engine (`smart_detection.py`) ğŸ†•
- âœ… Pure GenAI analysis (AI reads actual ticket content)
- âœ… Dynamic category discovery (not predefined)
- âœ… Evidence-based findings (every insight has ticket IDs)
- âœ… Confidence scoring (High/Medium/Low)
- âœ… Self-validation (AI challenges its own findings)
- âœ… Solution quality analysis (evaluates resolutions)
- âœ… Anomaly detection (duplicates, recurring issues, spikes)
- âœ… Fully configurable via `UserConfig` class
- âœ… Knowledge base ready (future RAG integration)
- âœ… Fallback to statistical analysis when AI unavailable

### Unified Analyzer (`analyze.py`) ğŸ†•
- âœ… Single command for complete analysis
- âœ… Beautiful Rich terminal UI with progress
- âœ… Multi-sheet Excel report (professionally formatted)
- âœ… Markdown executive summary
- âœ… PDF report generation
- âœ… Raw JSON data for integrations

### Analysis Capabilities
- âœ… True zombie detection (filters false positives)
- âœ… Entity analysis (vessels, stores, devices, accounts)
- âœ… Temporal pattern detection (emerging/declining issues)
- âœ… SLA compliance tracking (FRT + Resolution)
- âœ… Root cause analysis per category
- âœ… Customer/entity health scoring

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Freshdesk     â”‚â”€â”€â”€â”€â–¶â”‚   Extractor      â”‚â”€â”€â”€â”€â–¶â”‚   tickets.json  â”‚
â”‚   API           â”‚     â”‚   (v2.py)        â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                        â”‚   Ollama         â”‚              â”‚
                        â”‚   (qwen3:14b)    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                 â”‚                        â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚         Smart Detection Engine          â”‚
                        â”‚         (smart_detection.py)            â”‚
                        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        â”‚  â€¢ Category Discovery (AI-powered)      â”‚
                        â”‚  â€¢ Evidence Collection                  â”‚
                        â”‚  â€¢ Anomaly Detection                    â”‚
                        â”‚  â€¢ Solution Quality Analysis            â”‚
                        â”‚  â€¢ Self-Validation                      â”‚
                        â”‚  â€¢ Confidence Scoring                   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚           Unified Analyzer              â”‚
                        â”‚           (analyze.py)                  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚              Generated Reports                    â”‚
                â”‚  â€¢ analysis_report.xlsx (7+ sheets, formatted)   â”‚
                â”‚  â€¢ analysis_summary.md (executive summary)       â”‚
                â”‚  â€¢ analysis_summary.pdf (PDF version)            â”‚
                â”‚  â€¢ analysis_data.json (raw data)                 â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Prerequisites

### Required
- **Python 3.9+**
- **Freshdesk API Key** (with ticket read permissions)
- **8GB+ RAM** (for processing)

### Optional (for GenAI features)
- **Ollama** (local LLM runtime)
- **16GB+ RAM** recommended for 14B model (24GB ideal)

---

## Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-org/ftex.git
cd ftex
```

### 2. Create Virtual Environment (Recommended)

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

Or install manually:
```bash
# Core
pip install requests pandas rich python-dotenv

# Reports
pip install openpyxl markdown

# PDF (optional - choose one)
pip install weasyprint    # Option 1: Pure Python
# pip install pdfkit      # Option 2: Requires wkhtmltopdf
```

### 4. Install Ollama (Optional - for GenAI)

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama service
ollama serve

# Pull the recommended model (9.3GB)
ollama pull qwen3:14b
```

---

## Quick Start

### 1. Configure Environment

```bash
# Copy example and edit with your credentials
cp .env.example .env

# Edit .env file:
FRESHDESK_API_KEY=your_api_key_here
FRESHDESK_DOMAIN=yourcompany
FRESHDESK_GROUP_ID=48000615489
```

### 2. Test Connection

```bash
python3 run.py test
```

### 3. Run Full Pipeline

```bash
# Extract â†’ Analyze â†’ Report (all in one)
python3 run.py full --days 180
```

---

## CLI Reference

### All Commands Overview

```bash
python3 run.py test      # Test API connection
python3 run.py extract   # Download tickets from Freshdesk
python3 run.py analyze   # Run AI analysis + generate reports
python3 run.py full      # Run entire pipeline
python3 run.py --help    # Show help
```

---

### `test` - Check API Connection

```bash
python3 run.py test
python3 run.py test --api-key YOUR_KEY --domain yourcompany
```

---

### `extract` - Download Tickets

```bash
# Basic (uses .env settings)
python3 run.py extract

# With options
python3 run.py extract --days 90                    # Last 90 days
python3 run.py extract --days 365                   # Last year
python3 run.py extract --days 30 --no-attachments   # Skip attachments (faster)
python3 run.py extract --resume                     # Resume interrupted extraction
python3 run.py extract --group-id 48000615489       # Specific group
```

| Flag | Description | Default |
|------|-------------|---------|
| `--days`, `-d` | Days of history | 180 |
| `--group-id`, `-g` | Filter by group ID | From .env |
| `--no-attachments` | Skip downloading attachments | False |
| `--resume` | Resume from checkpoint | False |
| `--api-key`, `-k` | Override API key | From .env |

---

### `analyze` - Run AI Analysis

```bash
# Full AI analysis (requires Ollama running)
python3 run.py analyze

# Statistical only (no AI required)
python3 run.py analyze --no-ai

# Force re-discovery of categories
python3 run.py analyze --clear-cache

# Custom input/output
python3 run.py analyze --input data/tickets.json --output my_reports/
```

| Flag | Description | Default |
|------|-------------|---------|
| `--input`, `-i` | Input JSON file | output/tickets.json |
| `--output`, `-o` | Output directory | reports/ |
| `--no-ai` | Disable AI (statistical fallback) | False |
| `--clear-cache` | Clear cached categories | False |

**Analysis Outputs (Single Command):**
- `analysis_report.xlsx` - Multi-sheet Excel with all insights
- `analysis_summary.md` - Markdown executive summary
- `analysis_summary.pdf` - PDF version
- `analysis_data.json` - Raw data for integrations

---

### `full` - Complete Pipeline

```bash
# Full pipeline: Extract â†’ Analyze â†’ Report
python3 run.py full --days 180

# Skip extraction (use existing tickets.json)
python3 run.py full --skip-extract

# Without AI
python3 run.py full --days 90 --no-ai
```

| Flag | Description | Default |
|------|-------------|---------|
| `--days`, `-d` | Days of history | 180 |
| `--api-key`, `-k` | Freshdesk API key | From .env |
| `--group-id`, `-g` | Filter by group ID | From .env |
| `--skip-extract` | Use existing data | False |
| `--no-attachments` | Skip attachments | False |
| `--no-ai` | Disable AI analysis | False |

---

## Output Files

After running the full pipeline:

```
FTEX/
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ tickets.json              # All tickets (combined)
â”‚   â”œâ”€â”€ tickets.csv               # Flattened for Excel
â”‚   â”œâ”€â”€ tickets/                  # Individual ticket JSONs
â”‚   â””â”€â”€ checkpoints/              # Resume state
â”‚
â””â”€â”€ reports/
    â”œâ”€â”€ analysis_report.xlsx      # Multi-sheet Excel (7+ sheets)
    â”œâ”€â”€ analysis_summary.md       # Executive summary
    â”œâ”€â”€ analysis_summary.pdf      # PDF version
    â”œâ”€â”€ analysis_data.json        # Raw data
    â””â”€â”€ analysis_cache.json       # Cached categories
```

### Excel Report Sheets

| Sheet | Description | Key Metrics |
|-------|-------------|-------------|
| **Overview** | Summary metrics | Total tickets, zombie rate, date range |
| **Issue Categories** | AI-discovered categories | Count, zombies, resolution time, root causes |
| **Entities** | Per-entity analysis | Tickets, zombie rate, top issues |
| **Anomalies** | Detected anomalies | Type, severity, ticket IDs |
| **Zombie Tickets** | No-response tickets | ID, subject, reason |
| **SLA Performance** | Compliance metrics | FRT, resolution by priority |
| **Findings** | Evidence-based insights | Confidence, recommendations |

---

## Project Structure

```
FTEX/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ freshdesk_extractor_v2.py    # Ticket extraction with checkpointing
â”‚   â”‚   â””â”€â”€ test_freshdesk_api.py        # API connection tester
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â””â”€â”€ smart_detection.py           # Core analysis engine + UserConfig
â”‚   â”‚
â”‚   â””â”€â”€ analysis/
â”‚       â””â”€â”€ analyze.py                   # Unified analyzer + report generator
â”‚
â”œâ”€â”€ output/                    # Extracted data (gitignored)
â”‚   â”œâ”€â”€ tickets.json
â”‚   â”œâ”€â”€ tickets/
â”‚   â””â”€â”€ checkpoints/
â”‚
â”œâ”€â”€ reports/                   # Generated reports (gitignored)
â”‚
â”œâ”€â”€ run.py                     # CLI entry point
â”œâ”€â”€ config.py                  # Centralized configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                       # Your secrets (gitignored)
â”œâ”€â”€ .env.example               # Template for new users
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ README.md
```

---

## Configuration

### Environment Variables (`.env`)

Create a `.env` file in the project root:

```env
# Required
FRESHDESK_API_KEY=your_api_key_here
FRESHDESK_DOMAIN=yourcompany

# Optional
FRESHDESK_GROUP_ID=48000615489
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen3:14b

# Output (Optional)
FTEX_OUTPUT_DIR=.
FTEX_LOG_LEVEL=INFO
```

| Variable | Description | Required |
|----------|-------------|----------|
| `FRESHDESK_API_KEY` | Your Freshdesk API key | âœ… Yes |
| `FRESHDESK_DOMAIN` | Freshdesk subdomain (e.g., `navtor`) | âœ… Yes |
| `FRESHDESK_GROUP_ID` | Default group ID to filter | No |
| `OLLAMA_URL` | Ollama server URL | No |
| `OLLAMA_MODEL` | Preferred LLM model | No |

### `.env` vs `config.py`

| File | Purpose | Commit to Git? |
|------|---------|----------------|
| `.env` | Your secrets (API keys, domain) | âŒ Never |
| `config.py` | Code that reads `.env` + defaults | âœ… Yes |
| `.env.example` | Template for other users | âœ… Yes |

---

### Domain Customization (UserConfig)

Edit `src/shared/smart_detection.py` â†’ `UserConfig` class to configure for YOUR product:

```python
class UserConfig:
    # =========================================================================
    # ENTITY CONFIGURATION
    # What primary entity do you track tickets by?
    # =========================================================================
    ENTITY_NAME = "vessel"              # or "store", "device", "account"
    ENTITY_NAME_PLURAL = "vessels"
    
    # Regex patterns to extract entity from ticket text
    ENTITY_PATTERNS = [
        r'(?:vessel|ship|mv|m/v)[:\s]+([A-Z][A-Za-z0-9\s\-]{2,25})',
        r'imo[:\s]*(\d{7})',
    ]
    
    # =========================================================================
    # PRODUCT CONTEXT
    # =========================================================================
    PRODUCT_NAME = "Digital Logbook System"
    PRODUCT_DESCRIPTION = """
    Maritime compliance software for electronic record-keeping.
    """
    PRODUCT_MODULES = ["Signature", "Sync", "ORB", "Deck Log"]
    
    # =========================================================================
    # KNOWLEDGE BASE (RAG-Ready)
    # =========================================================================
    GLOSSARY = {
        "ORB": "Oil Record Book - maritime compliance document",
        "IMO": "International Maritime Organization",
    }
    
    KNOWN_SOLUTIONS = {
        "sync_failure": {
            "steps": ["Clear local cache", "Force sync from server"],
            "root_cause": "Cache corruption or network timeout",
            "prevention": "Implement automatic cache validation"
        },
    }
    
    ESCALATION_TRIGGERS = [
        "data loss", "compliance", "audit", "legal", "security breach"
    ]
    
    # =========================================================================
    # THRESHOLDS
    # =========================================================================
    DUPLICATE_REQUEST_DAYS = 365
    DUPLICATE_REQUEST_KEYWORDS = ["activation", "license", "renewal"]
    RECURRING_ISSUE_THRESHOLD = 3
    HIGH_FREQUENCY_MULTIPLIER = 3.0
    SPIKE_MULTIPLIER = 2.0
    
    # Confidence scoring
    HIGH_CONFIDENCE_MIN_EVIDENCE = 10
    MEDIUM_CONFIDENCE_MIN_EVIDENCE = 3
    
    # AI settings
    AI_BATCH_SIZE = 30
    AI_VALIDATION_ENABLED = True
    CACHE_CATEGORIES = True
```

---

### SLA Configuration

Edit `config.py` to set SLA thresholds:

```python
@dataclass  
class SLAConfig:
    first_response: Dict[str, int] = field(default_factory=lambda: {
        'Urgent': 1,   # 1 hour
        'High': 4,     # 4 hours
        'Medium': 8,   # 8 hours
        'Low': 24,     # 24 hours
    })
    resolution: Dict[str, int] = field(default_factory=lambda: {
        'Urgent': 4,    # 4 hours
        'High': 24,     # 1 day
        'Medium': 72,   # 3 days
        'Low': 168,     # 7 days
    })
```

---

## Analysis Pipeline

The analysis engine follows a 6-stage evidence-based approach:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: Data Foundation                                    â”‚
â”‚ â””â”€â”€ Extract facts: counts, dates, statuses (undisputable)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ STAGE 2: AI Category Discovery                              â”‚
â”‚ â””â”€â”€ AI reads tickets, proposes categories + keywords        â”‚
â”‚ â””â”€â”€ Categories cached for consistency across runs           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ STAGE 3: Evidence Collection                                â”‚
â”‚ â””â”€â”€ Map ALL tickets to categories                           â”‚
â”‚ â””â”€â”€ Collect ticket IDs as evidence                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ STAGE 4: Anomaly Detection                                  â”‚
â”‚ â””â”€â”€ Duplicate requests (same entity, same issue)            â”‚
â”‚ â””â”€â”€ Recurring issues (entity has 3+ of same type)           â”‚
â”‚ â””â”€â”€ High-frequency entities (>3x average tickets)           â”‚
â”‚ â””â”€â”€ Monthly spikes (>2x average)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ STAGE 5: Solution Quality Analysis                          â”‚
â”‚ â””â”€â”€ Evaluate resolved ticket solutions                      â”‚
â”‚ â””â”€â”€ Compare against known solutions (knowledge base)        â”‚
â”‚ â””â”€â”€ Score: Excellent, Good, Acceptable, Poor                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ STAGE 6: Finding Generation + Validation                    â”‚
â”‚ â””â”€â”€ Generate evidence-based findings                        â”‚
â”‚ â””â”€â”€ Calculate confidence (High/Medium/Low)                  â”‚
â”‚ â””â”€â”€ AI self-validates findings                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Confidence Scoring

| Confidence | Criteria |
|------------|----------|
| **High** ğŸŸ¢ | 10+ supporting tickets, no contradictions |
| **Medium** ğŸŸ¡ | 3-9 supporting tickets |
| **Low** ğŸ”´ | <3 tickets or unvalidated hypothesis |

### True Zombie Detection

FTEX filters out false positives:

| Detected | Actual Status | FTEX Classification |
|----------|---------------|---------------------|
| No conversations | No response | âœ… True Zombie |
| Customer said "Thanks!" | Acknowledgment | âŒ False Positive |
| Customer said "Got it, closing" | Confirmation | âŒ False Positive |
| Customer asked follow-up | Needs response | âœ… True Zombie |

---

## Customization Examples

### Maritime Industry
```python
ENTITY_NAME = "vessel"
ENTITY_PATTERNS = [r'(?:vessel|ship|mv)[:\s]+([A-Z][A-Za-z\-]+)']
PRODUCT_MODULES = ["Signature", "Logbook", "Sync", "Compliance"]
GLOSSARY = {"ORB": "Oil Record Book", "IMO": "International Maritime Organization"}
```

### Retail / POS
```python
ENTITY_NAME = "store"
ENTITY_PATTERNS = [r'(?:store|location|branch)[:\s#]+(\w+)']
PRODUCT_MODULES = ["POS", "Inventory", "Payments", "Reports"]
DUPLICATE_REQUEST_KEYWORDS = ["terminal", "license", "activation"]
```

### SaaS Platform
```python
ENTITY_NAME = "account"
ENTITY_PATTERNS = [r'(?:account|customer|company)[:\s]+([A-Za-z0-9\s]+)']
PRODUCT_MODULES = ["Auth", "API", "Dashboard", "Billing", "Integrations"]
ESCALATION_TRIGGERS = ["data loss", "security", "sso", "downtime"]
```

### IoT / Hardware
```python
ENTITY_NAME = "device"
ENTITY_PATTERNS = [r'(?:device|serial|unit)[:\s]+([A-Z0-9\-]+)']
PRODUCT_MODULES = ["Firmware", "Connectivity", "Sensors", "Gateway"]
RECURRING_ISSUE_THRESHOLD = 2  # Stricter for hardware
```

---

## Troubleshooting

### Extraction Issues

**API Rate Limit Hit**
```
The script auto-throttles at 40 req/min. If you see rate limit errors:
1. Wait 1 hour for quota reset
2. Use --resume to continue
```

**Mac Sleep Interruption**
```bash
caffeinate -i python3 run.py extract --days 180
```

**Resume Not Working**
```bash
ls output/checkpoints/
# Should see: ticket_ids.json, extraction_state.json
```

### Analysis Issues

**Ollama Not Found**
```bash
curl http://localhost:11434/api/tags
# If not running:
ollama serve
```

**Out of Memory**
```bash
# Use smaller model
ollama pull qwen3:8b

# Or run without GenAI
python3 run.py analyze --no-ai
```

**Categories Not Matching**
```bash
# Clear cache and re-discover
python3 run.py analyze --clear-cache
```

### Report Issues

**PDF Not Generated**
```bash
# Install weasyprint
pip install weasyprint

# Or use pdfkit (requires wkhtmltopdf)
pip install pdfkit
# macOS: brew install wkhtmltopdf
# Linux: apt-get install wkhtmltopdf
```

**Excel Formatting Issues**
```bash
pip install --upgrade openpyxl
```

---

## Roadmap

### Phase 1 âœ… (Complete)
- [x] Ticket extraction with checkpointing
- [x] Smart zombie detection (filters false positives)
- [x] Self-validating AI analysis
- [x] Evidence-based findings
- [x] Solution quality analysis
- [x] Multi-sheet Excel reports
- [x] Unified CLI entry point
- [x] Configurable for any domain

### Phase 2 ğŸš§ (In Progress)
- [ ] Web dashboard for real-time monitoring
- [ ] Scheduled extraction (cron/Airflow)
- [ ] Slack/Teams integration for alerts
- [ ] Customer health scoring dashboard

### Phase 3 ğŸ“‹ (Planned)
- [ ] RAG integration for knowledge base
- [ ] Historical trend analysis
- [ ] Predictive ticket routing
- [ ] Agent performance coaching

### Phase 4 ğŸ”® (Vision)
- [ ] SaaS product offering
- [ ] Integration marketplace (Zendesk, Intercom, etc.)
- [ ] AI-powered auto-responses
- [ ] Customer success automation

---

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Acknowledgments

- [Freshdesk API](https://developers.freshdesk.com/) for ticket data
- [Ollama](https://ollama.ai/) for local LLM inference
- [Rich](https://rich.readthedocs.io/) for beautiful terminal UI
- [Pandas](https://pandas.pydata.org/) for data processing
- [OpenPyXL](https://openpyxl.readthedocs.io/) for Excel generation

---

<p align="center">
  <b>Built with â¤ï¸ for Support Operations Teams Everywhere</b>
</p>